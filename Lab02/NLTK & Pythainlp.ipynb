{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Ue7VURN3j000czponf9GbhohvuC2LDsY","timestamp":1705543250898}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"447a123931b0465d9836f6fe2d38a2dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f5dc40770b6547a887ea0c5671403a84","IPY_MODEL_01664120a4364798bb89ebe303725d63","IPY_MODEL_96f04c2992d94651b7673ee3b69f5924"],"layout":"IPY_MODEL_56e89d92c5374ddcad0fb790e9eb8ddf"}},"f5dc40770b6547a887ea0c5671403a84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10383374dd2343ee84f120023812bb54","placeholder":"​","style":"IPY_MODEL_f642252716e44969ba20d5b9c5efd16c","value":"100%"}},"01664120a4364798bb89ebe303725d63":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2aef80e0e0fc42d1b23ddf95b597fd1f","max":1872468,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c175f78b89764f76803e564a2d80f56c","value":1872468}},"96f04c2992d94651b7673ee3b69f5924":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99677a9113f44f7e93fd2b756943d37b","placeholder":"​","style":"IPY_MODEL_8c355a76379f4b68b9976957ca0bf0a3","value":" 1872468/1872468 [00:00&lt;00:00, 26267082.36it/s]"}},"56e89d92c5374ddcad0fb790e9eb8ddf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10383374dd2343ee84f120023812bb54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f642252716e44969ba20d5b9c5efd16c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2aef80e0e0fc42d1b23ddf95b597fd1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c175f78b89764f76803e564a2d80f56c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"99677a9113f44f7e93fd2b756943d37b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c355a76379f4b68b9976957ca0bf0a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6fb903ae245548f1be929c83cefe2c13":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6d63b458d3c34c9cb5ec12eaebea20d4","IPY_MODEL_9474e890177a41e2a7df15f2daf95fe2","IPY_MODEL_d2abf9e6002e4dbdb9e7537800ea57ed"],"layout":"IPY_MODEL_20e2f5df4f1f4decb0453bc15c0c5b10"}},"6d63b458d3c34c9cb5ec12eaebea20d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff6ebbd5d7fa4647920b62af9f19653a","placeholder":"​","style":"IPY_MODEL_da51e0970031479398372667e77bd406","value":"100%"}},"9474e890177a41e2a7df15f2daf95fe2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8121fa30f9924ca4aa1eaf13f082a42f","max":62452646,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2aead25f7b5a4989a0960da9856ea2ed","value":62452646}},"d2abf9e6002e4dbdb9e7537800ea57ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4bf6b96174e48d59d913ce6800af28d","placeholder":"​","style":"IPY_MODEL_6a01748484f646f1bcf7c9c0437cb844","value":" 62452646/62452646 [00:00&lt;00:00, 117105721.83it/s]"}},"20e2f5df4f1f4decb0453bc15c0c5b10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff6ebbd5d7fa4647920b62af9f19653a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da51e0970031479398372667e77bd406":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8121fa30f9924ca4aa1eaf13f082a42f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2aead25f7b5a4989a0960da9856ea2ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b4bf6b96174e48d59d913ce6800af28d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a01748484f646f1bcf7c9c0437cb844":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# URL: http://tinyurl.com/b4ejxkca"],"metadata":{"id":"LmDI9PySblD8"}},{"cell_type":"markdown","source":["# NLTK"],"metadata":{"id":"Ia9HFQz3nn7P"}},{"cell_type":"markdown","source":["## Introduction to Natural Language Toolkit (NLTK) ใช้สำหรับ Eng มากกว่า\n","- Brief overview of NLTK.\n","\n","  NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.\n"],"metadata":{"id":"T6AINTHnbvJ1"}},{"cell_type":"markdown","source":["## Setting Up NLTK\n","- Installing NLTK using pip.\n","- Downloading NLTK data."],"metadata":{"id":"AwjifekXbzom"}},{"cell_type":"code","source":["!pip install nltk"],"metadata":{"id":"E0aLwu4TexWy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705543653572,"user_tz":-420,"elapsed":5678,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"f5c0bb42-8ba9-4996-9c38-2b52720e7230"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"]}]},{"cell_type":"code","source":["import nltk\n","# nltk.download(\"all\")\n","# print(\"NLTK is successfully installed and data is downloaded.\")"],"metadata":{"id":"MvHDl6Boem1L","executionInfo":{"status":"ok","timestamp":1705543664471,"user_tz":-420,"elapsed":2469,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Basic NLTK Operations\n","- Tokenization: Breaking text into words or sentences.\n","- Stopwords: Identifying and removing common words."],"metadata":{"id":"WeVcIHnib4eG"}},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk.corpus import stopwords\n","\n","nltk.download(\"punkt\")\n","nltk.download(\"stopwords\")\n","\n","# Example Text\n","text = \"NLTK is a powerful library for natural language processing. It makes NLP tasks easy and efficient.\"\n","\n","# Tokenization\n","words = word_tokenize(text)\n","sentences = sent_tokenize(text)\n","\n","# Stopwords บอกขนาดเพื่อ content คำที่ต้องการ เป็นประเด็นหลัก\n","stop_words = set(stopwords.words(\"english\"))\n","filtered_words = [word for word in words if word.lower() not in stop_words]\n","\n","print(\"Tokenized Words:\", words)\n","print(\"Tokenized Sentences:\", sentences)\n","print(\"Filtered Words (excluding stopwords):\", filtered_words)"],"metadata":{"id":"M-ONbHgdfALn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705543938747,"user_tz":-420,"elapsed":543,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"a3ff1b76-bc35-4f30-a4b7-1df473510310"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized Words: ['NLTK', 'is', 'a', 'powerful', 'library', 'for', 'natural', 'language', 'processing', '.', 'It', 'makes', 'NLP', 'tasks', 'easy', 'and', 'efficient', '.']\n","Tokenized Sentences: ['NLTK is a powerful library for natural language processing.', 'It makes NLP tasks easy and efficient.']\n","Filtered Words (excluding stopwords): ['NLTK', 'powerful', 'library', 'natural', 'language', 'processing', '.', 'makes', 'NLP', 'tasks', 'easy', 'efficient', '.']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["## Part-of-Speech Tagging\n","- Understanding parts of speech.\n","- Using NLTK for part-of-speech tagging."],"metadata":{"id":"oa9-mr9DcADK"}},{"cell_type":"code","source":["# Part-of-Speech Tagging Example\n","nltk.download('averaged_perceptron_tagger')\n","pos_tags = nltk.pos_tag(words)\n","print(\"Part-of-Speech Tags:\", pos_tags)"],"metadata":{"id":"uIDHOFAefJ85","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705544136407,"user_tz":-420,"elapsed":326,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"c6a443dd-4554-4987-f6bb-df7c30a46a83"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Part-of-Speech Tags: [('NLTK', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('powerful', 'JJ'), ('library', 'NN'), ('for', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('.', '.'), ('It', 'PRP'), ('makes', 'VBZ'), ('NLP', 'NNP'), ('tasks', 'NNS'), ('easy', 'JJ'), ('and', 'CC'), ('efficient', 'JJ'), ('.', '.')]\n"]}]},{"cell_type":"markdown","source":["## Text Analysis with NLTK\n","- Frequency distribution of words.\n","- Concordance and collocations.\n","- Lexical diversity."],"metadata":{"id":"WC6MfJnzcLsD"}},{"cell_type":"code","source":["import nltk\n","nltk.download('gutenberg')\n","\n","from nltk import FreqDist\n","from nltk.text import Text\n","\n","text = \"NLTK is a powerful library for natural language processing. It makes NLP tasks easy and efficient. NLTK is a leading platform for building Python programs to work with human language data.\"\n","words = word_tokenize(text)\n","\n","# Frequency Distribution\n","freq_dist = FreqDist(words)\n","print(\"Frequency Distribution:\", freq_dist.most_common())\n","\n","print(\"###########################\")\n","\n","# Concordance\n","text = Text(words)\n","concordance_results = text.concordance(\"language\")\n","print(concordance_results)\n","\n","print(\"###########################\")\n","\n","# concordance from the corpus\n","text = Text(nltk.corpus.gutenberg.words('melville-moby_dick.txt'))\n","concordance_results = text.concordance(\"natural\")\n","print(concordance_results)\n","\n","print(\"###########################\")\n","\n","# Collocations\n","collocations = text.collocation_list()\n","print(\"Collocations:\", collocations)"],"metadata":{"id":"BgF9oCfpfQqH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705544228029,"user_tz":-420,"elapsed":1751,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"7ed9e113-c14a-4360-877f-948838bc690f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/gutenberg.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Frequency Distribution: [('.', 3), ('NLTK', 2), ('is', 2), ('a', 2), ('for', 2), ('language', 2), ('powerful', 1), ('library', 1), ('natural', 1), ('processing', 1), ('It', 1), ('makes', 1), ('NLP', 1), ('tasks', 1), ('easy', 1), ('and', 1), ('efficient', 1), ('leading', 1), ('platform', 1), ('building', 1), ('Python', 1), ('programs', 1), ('to', 1), ('work', 1), ('with', 1), ('human', 1), ('data', 1)]\n","###########################\n","Displaying 2 of 2 matches:\n"," is a powerful library for natural language processing . It makes NLP tasks ea\n","Python programs to work with human language data .\n","None\n","###########################\n","Displaying 25 of 36 matches:\n"," unite in a man of greatly superior natural force , with a globular brain and a\n","pit ! ye insult me , man ; past all natural bearing , ye insult me . It ' s an \n"," stayed below . And all this seemed natural enough ; especially as in the merch\n","r a seaman , and endued with a deep natural reverence , the wild watery lonelin\n","ferences , that some departments of natural history become so repellingly intri\n","a portion of the whole term of your natural life , should be so sadly destitute\n","ar impressions effaced . For in his Natural History , the Baron himself affirms\n","hat so much invested the whale with natural terror , as that unexampled , intel\n"," madness , not one jot of his great natural intellect had perished . That befor\n","rs might be naught . Though in many natural objects , whiteness refiningly enha\n","ng at such vast altitudes , and the natural conceit of what a fearfulness it wo\n","e consider that other theory of the natural philosophers , that all other earth\n","ay induce in some minds , as to the natural verity of the main points of this a\n"," a good degree continue true to the natural , nominal purpose of the Pequod ' s\n","g in concert : then , how much more natural that upon the illimitable Pine Barr\n","away King ' s Mills ; how much more natural , I say , that under such circumsta\n"," most conscientious compilations of Natural History for the benefit of the youn\n","us Baron . In 1836 , he published a Natural History of Whales , in which he giv\n","ea battle - pieces of Garnery . The natural aptitude of the French for seizing \n","ds of bone , as they stand in their natural order , there are certain curious m\n","ept continually playing , while the natural spout - hole in his head was only a\n","id vicissitudes of the chase , this natural line , with the maternal end loose \n","sly showed him off to ten times the natural lustre with which in his native Tol\n","look ghastly . To - morrow , in the natural sun , the skies will be bright ; th\n","haling good cheer is not normal and natural , but incidental and particular ; a\n","None\n","###########################\n","Collocations: [('Sperm', 'Whale'), ('Moby', 'Dick'), ('White', 'Whale'), ('old', 'man'), ('Captain', 'Ahab'), ('sperm', 'whale'), ('Right', 'Whale'), ('Captain', 'Peleg'), ('New', 'Bedford'), ('Cape', 'Horn'), ('cried', 'Ahab'), ('years', 'ago'), ('lower', 'jaw'), ('never', 'mind'), ('Father', 'Mapple'), ('cried', 'Stubb'), ('chief', 'mate'), ('white', 'whale'), ('ivory', 'leg'), ('one', 'hand')]\n"]}]},{"cell_type":"markdown","source":["## Stemming and Lemmatization\n","- Introduction to stemming.\n","- Introduction to lemmatization.\n","- NLTK tools for stemming and lemmatization."],"metadata":{"id":"hxGCkPSmcUaN"}},{"cell_type":"code","source":["import nltk\n","nltk.download('wordnet')\n","\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","\n","# Example Words\n","words_to_stem = [\"running\", \"better\", \"cats\", \"gone\"]\n","\n","# Stemming\n","stemmer = PorterStemmer()\n","stemmed_words = [stemmer.stem(word) for word in words_to_stem]\n","print(\"Stemmed Words:\", stemmed_words)\n","\n","# Lemmatization\n","lemmatizer = WordNetLemmatizer()\n","lemmatized_words = [lemmatizer.lemmatize(word) for word in words_to_stem]\n","print(\"Lemmatized Words:\", lemmatized_words)"],"metadata":{"id":"GQGoeJBCfWIe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705544515512,"user_tz":-420,"elapsed":2331,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"5c2cc163-271f-4ed4-90a2-3f7669c775c4"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["Stemmed Words: ['run', 'better', 'cat', 'gone']\n","Lemmatized Words: ['running', 'better', 'cat', 'gone']\n"]}]},{"cell_type":"markdown","source":["## Named Entity Recognition (NER)\n","- Identifying entities in text.\n","- NLTK's NER capabilities."],"metadata":{"id":"3KRQxOP4cZRj"}},{"cell_type":"code","source":["import nltk\n","nltk.download('maxent_ne_chunker')\n","nltk.download('words')\n","\n","# Named Entity Recognition Example\n","ner_result = nltk.ne_chunk(pos_tags)\n","print(\"Named Entities:\", ner_result)"],"metadata":{"id":"mQoKlBwdfcYE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705544791127,"user_tz":-420,"elapsed":923,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"515f0d09-d862-4b26-f319-52cafbd4d6c7"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Named Entities: (S\n","  (ORGANIZATION NLTK/NNP)\n","  is/VBZ\n","  a/DT\n","  powerful/JJ\n","  library/NN\n","  for/IN\n","  natural/JJ\n","  language/NN\n","  processing/NN\n","  ./.\n","  It/PRP\n","  makes/VBZ\n","  (ORGANIZATION NLP/NNP)\n","  tasks/NNS\n","  easy/JJ\n","  and/CC\n","  efficient/JJ\n","  ./.)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n"]}]},{"cell_type":"markdown","source":["## Sentiment Analysis with NLTK\n","- Introduction to sentiment analysis.\n","- Using NLTK for sentiment analysis."],"metadata":{"id":"IkM37S9xcdsB"}},{"cell_type":"code","source":["import nltk\n","nltk.download('vader_lexicon')\n","\n","from nltk.sentiment import SentimentIntensityAnalyzer\n","\n","# Example Sentence\n","sentence = \"NLTK is amazing! I love using it for NLP tasks.\"\n","\n","# Sentiment Analysis\n","sia = SentimentIntensityAnalyzer()\n","sentiment_score = sia.polarity_scores(sentence)\n","print(\"Sentiment Score:\", sentiment_score)"],"metadata":{"id":"ng8f9pibfeym","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705544909429,"user_tz":-420,"elapsed":344,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"6e531fc0-64a5-4990-daa4-df2c972c0c96"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentiment Score: {'neg': 0.0, 'neu': 0.458, 'pos': 0.542, 'compound': 0.8516}\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"]}]},{"cell_type":"markdown","source":["## Advanced in NLTK\n","- Advanced tokenization techniques.\n","- Chunking and parsing.\n","- Machine learning with NLTK."],"metadata":{"id":"N_9d_5X5chne"}},{"cell_type":"code","source":["from nltk.tokenize import MWETokenizer, TweetTokenizer\n","\n","# Multi-Word Expression Tokenization\n","mwe_tokenizer = MWETokenizer([(\"natural\", \"language\"), (\"processing\", \"tasks\")])\n","mwe_tokens = mwe_tokenizer.tokenize(words)\n","print(\"Multi-Word Expression Tokenization:\", mwe_tokens)\n","\n","# Tweet Tokenization\n","tweet_tokenizer = TweetTokenizer()\n","tweet_tokens = tweet_tokenizer.tokenize(\"NLTK is awesome! #NLP #Python\")\n","print(\"Tweet Tokenization:\", tweet_tokens)"],"metadata":{"id":"QNekYmcGfkJm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705545038022,"user_tz":-420,"elapsed":323,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"3621cc7e-a9c8-450f-c620-24ed950c88f5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Multi-Word Expression Tokenization: ['NLTK', 'is', 'a', 'powerful', 'library', 'for', 'natural_language', 'processing', '.', 'It', 'makes', 'NLP', 'tasks', 'easy', 'and', 'efficient', '.', 'NLTK', 'is', 'a', 'leading', 'platform', 'for', 'building', 'Python', 'programs', 'to', 'work', 'with', 'human', 'language', 'data', '.']\n","Tweet Tokenization: ['NLTK', 'is', 'awesome', '!', '#NLP', '#Python']\n"]}]},{"cell_type":"code","source":["# Chunking and Parsing\n","import os\n","import nltk\n","from nltk import RegexpParser\n","from nltk.tokenize import word_tokenize\n","from IPython.display import Image\n","\n","# Example Sentence\n","chunking_sentence = \"The black cat chased the white mouse.\"\n","\n","# Define a simple grammar for NP (Noun Phrase) chunking\n","grammar = r\"NP: {<DT>?<JJ>*<NN>}\"\n","\n","# Create a chunk parser\n","chunk_parser = RegexpParser(grammar)\n","\n","words = word_tokenize(chunking_sentence)\n","pos_tags = nltk.pos_tag(words)\n","\n","# Apply chunking\n","tree = chunk_parser.parse(pos_tags)\n","print(\"Chunking Example:\", tree)\n","# tree.draw()\n"],"metadata":{"id":"OXPvRTGZfnRs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705545109764,"user_tz":-420,"elapsed":360,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"3501d5ce-2962-4e26-9439-f258ebc71725"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Chunking Example: (S\n","  (NP The/DT black/JJ cat/NN)\n","  chased/VBD\n","  (NP the/DT white/JJ mouse/NN)\n","  ./.)\n"]}]},{"cell_type":"markdown","source":["example of draw function in the computer.<br>\n","<img src=\"https://www.nltk.org/_images/tree.gif\">"],"metadata":{"id":"5PGkmeor7IKf"}},{"cell_type":"code","source":["# Machine Learning with NLTK - Classification\n","from nltk.classify import NaiveBayesClassifier\n","from nltk.classify.util import accuracy\n","\n","# Example Dataset\n","training_data = [\n","    ({\"feature1\": \"value1\", \"feature2\": \"value2\"}, \"class1\"),\n","    ({\"feature1\": \"value3\", \"feature2\": \"value4\"}, \"class2\"),\n","    # Add more examples...\n","]\n","\n","# Train a Naive Bayes Classifier\n","classifier = NaiveBayesClassifier.train(training_data)\n","\n","# Example Classification\n","test_instance = {\"feature1\": \"value5\", \"feature2\": \"value6\"}\n","classification_result = classifier.classify(test_instance)\n","print(\"Classification Result:\", classification_result)\n","\n","# Evaluate Classifier Accuracy\n","accuracy_score = accuracy(classifier, training_data)\n","print(\"Classifier Accuracy:\", accuracy_score)"],"metadata":{"id":"ypXDKmI1fqsV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705545303187,"user_tz":-420,"elapsed":341,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"0d18fc9b-c00f-42f4-d5e0-42e6fbefd85f"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Classification Result: class2\n","Classifier Accuracy: 1.0\n"]}]},{"cell_type":"markdown","source":["## Case Study\n","- Applying NLTK techniques to a real-world dataset."],"metadata":{"id":"JdJKOnpLcooc"}},{"cell_type":"code","source":["import nltk\n","nltk.download('movie_reviews')\n","\n","# Case Study: Analyzing Movie Reviews\n","from nltk.corpus import movie_reviews\n","from nltk import FreqDist, NaiveBayesClassifier\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","\n","# Load movie reviews dataset from NLTK\n","documents = [(list(movie_reviews.words(fileid)), category)\n","             for category in movie_reviews.categories()\n","             for fileid in movie_reviews.fileids(category)]\n","\n","# Shuffle the documents to ensure randomness\n","import random\n","random.shuffle(documents)\n","\n","# Tokenization and stopwords removal\n","all_words = [word.lower() for word in movie_reviews.words()]\n","filtered_words = [word.lower() for word in all_words if word.isalpha() and word.lower() not in stopwords.words(\"english\")]\n","\n","# Extract the 2000 most common words as features\n","word_features = FreqDist(filtered_words).most_common(2000)\n","word_features = [word for word, _ in word_features]\n","\n","# Define a function to extract features from a document\n","def document_features(document):\n","    document_words = set(document)\n","    features = {word: (word in document_words) for word in word_features}\n","    return features\n","\n","# Extract features for each document\n","featuresets = [(document_features(d), c) for (d, c) in documents]\n","\n","# Split the dataset into a training set and a testing set\n","train_set, test_set = featuresets[:1600], featuresets[1600:]\n","\n","# Train a Naive Bayes classifier\n","classifier = NaiveBayesClassifier.train(train_set)\n","\n","# Evaluate the classifier on the testing set\n","accuracy = nltk.classify.accuracy(classifier, test_set)\n","print(\"Classifier Accuracy:\", accuracy)\n","\n","# Example of sentiment analysis\n","example_text = \"This movie is amazing! I loved every moment of it.\"\n","tokens = word_tokenize(example_text.lower())\n","features = document_features(tokens)\n","\n","sentiment = classifier.classify(features)\n","print(\"Sentiment:\", sentiment)"],"metadata":{"id":"qgxBU4SPfu92","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705546343471,"user_tz":-420,"elapsed":139207,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"10abba09-d909-41ed-ae95-831c3a503fd8"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n","[nltk_data]   Package movie_reviews is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Classifier Accuracy: 0.8175\n","Sentiment: neg\n"]}]},{"cell_type":"markdown","source":["## Discussion on challenges and solutions.\n","    Tokenization Challenges:\n","        Challenge: Dealing with tokenization errors, especially in languages with complex grammatical structures.\n","        Solution: Use NLTK's more advanced tokenizers like TweetTokenizer or customize tokenization rules based on the specific language or domain.\n","\n","    Stopwords Removal Challenges:\n","        Challenge: Deciding which words to include or exclude from stopwords.\n","        Solution: Customize the list of stopwords based on the specific requirements of the analysis. Consider domain-specific or project-specific stopwords.\n","\n","    Part-of-Speech Tagging Challenges:\n","        Challenge: Ambiguity in part-of-speech tagging, especially in context-dependent cases.\n","        Solution: Experiment with different POS tagging models and fine-tune as needed. Evaluate the accuracy and performance of the chosen model on the specific type of text.\n","\n","    Named Entity Recognition (NER) Challenges:\n","        Challenge: Handling entities with multiple words or complex structures.\n","        Solution: Utilize more advanced NER models, and consider post-processing steps to handle complex entities. NLTK's ne_chunk can be a starting point.\n","\n","    Sentiment Analysis Challenges:\n","        Challenge: Addressing the subjectivity and context dependency of sentiment.\n","        Solution: Incorporate more sophisticated sentiment analysis models, such as machine learning classifiers, and consider using pre-trained models. Also, consider incorporating context information to enhance accuracy.\n","\n","    Stemming and Lemmatization Challenges:\n","        Challenge: Overstemming or understemming issues.\n","        Solution: Choose an appropriate stemming or lemmatization algorithm based on the characteristics of the text. Evaluate the impact on downstream tasks and fine-tune as needed.\n","\n","    Handling Large Datasets Challenges:\n","        Challenge: Memory and processing constraints when working with large text corpora.\n","        Solution: Implement efficient processing strategies, such as batch processing, and consider distributed computing frameworks if applicable. Optimize memory usage and load data incrementally if necessary.\n","\n","    Machine Learning Model Challenges:\n","        Challenge: Finding an appropriate model and dealing with imbalanced datasets.\n","        Solution: Experiment with various machine learning models, including ensemble methods. Address imbalanced datasets through techniques such as oversampling, undersampling, or using evaluation metrics suitable for imbalanced classes.\n","\n","    Generalization Challenges:\n","        Challenge: Ensuring that models generalize well to different domains.\n","        Solution: Train models on diverse datasets and test on a representative set of data. Use transfer learning or domain adaptation techniques if applicable.\n","\n","    Interpreting Results Challenges:\n","        Challenge: Interpreting and explaining the results of NLP analyses.\n","        Solution: Utilize visualization techniques, conduct feature importance analysis, and document the preprocessing steps and model decisions. Provide clear explanations of the limitations and potential biases."],"metadata":{"id":"0J7g9mvumvRq"}},{"cell_type":"markdown","source":["Resources and Further Learning\n","- Documentation: https://www.nltk.org/howto.html"],"metadata":{"id":"XhUYSLNnc12A"}},{"cell_type":"markdown","source":["# Pythainlp"],"metadata":{"id":"EvU61dPRnw96"}},{"cell_type":"markdown","source":["## Introduction to Pythainlp\n","- Introduction to PyThaiNLP library for natural language processing in Thai."],"metadata":{"id":"PQ9B1vDrn12o"}},{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"q2Fi3K53pHPJ"}},{"cell_type":"code","source":["!pip install pythainlp\n","# for using TF-IDF\n","!pip install scikit-learn\n","# for using NER\n","!pip install python-crfsuite"],"metadata":{"id":"bgWn56aPpLjD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705546423037,"user_tz":-420,"elapsed":17736,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"8a8d3389-4cb3-4cbb-9aec-bac4899e8da7"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pythainlp\n","  Downloading pythainlp-4.0.2-py3-none-any.whl (13.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pythainlp) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2023.11.17)\n","Installing collected packages: pythainlp\n","Successfully installed pythainlp-4.0.2\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n","Collecting python-crfsuite\n","  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: python-crfsuite\n","Successfully installed python-crfsuite-0.9.10\n"]}]},{"cell_type":"markdown","source":["## Basic Text Processing"],"metadata":{"id":"9mUKRzcZpOYU"}},{"cell_type":"code","source":["!pip install attacut"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9BaBxwpElYuM","executionInfo":{"status":"ok","timestamp":1705548037115,"user_tz":-420,"elapsed":9984,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"b8bf353d-cf91-44ef-91c7-8daeb1bea0ce"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting attacut\n","  Downloading attacut-1.0.6-py3-none-any.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docopt>=0.6.2 (from attacut)\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting fire>=0.1.3 (from attacut)\n","  Downloading fire-0.5.0.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting nptyping>=0.2.0 (from attacut)\n","  Downloading nptyping-2.5.0-py3-none-any.whl (37 kB)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from attacut) (1.23.5)\n","Requirement already satisfied: pyyaml>=5.1.2 in /usr/local/lib/python3.10/dist-packages (from attacut) (6.0.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from attacut) (1.16.0)\n","Collecting ssg>=0.0.4 (from attacut)\n","  Downloading ssg-0.0.8-py3-none-any.whl (473 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.8/473.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from attacut) (2.1.0+cu121)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.1.3->attacut) (2.4.0)\n","Requirement already satisfied: python-crfsuite>=0.9.6 in /usr/local/lib/python3.10/dist-packages (from ssg>=0.0.4->attacut) (0.9.10)\n","Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.10/dist-packages (from ssg>=0.0.4->attacut) (4.66.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.2.0->attacut) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.2.0->attacut) (1.3.0)\n","Building wheels for collected packages: docopt, fire\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=7e59a371f4447951f499c26184ed8afe4b5dfcc96e9401e7d252f587643dbfc8\n","  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=06c15faac38de2d1edd6f4d86180ad2be8f73b5b8dcb4a710ad12f3cbdf75878\n","  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n","Successfully built docopt fire\n","Installing collected packages: docopt, nptyping, fire, ssg, attacut\n","Successfully installed attacut-1.0.6 docopt-0.6.2 fire-0.5.0 nptyping-2.5.0 ssg-0.0.8\n"]}]},{"cell_type":"code","source":["import pythainlp\n","\n","text = \"วันนี้ตื่นสายจึงเข้าโรงเรียนช้าจากนั้นก็ไปหาขนมกินรูปร่างดอกไม้เพราะเมื่อเช้ายังไม่ได้กินอะไรมากเลย\"\n","tokens = pythainlp.word_tokenize(text,engine='attacut')\n","print(\"Tokenized:\", tokens)"],"metadata":{"id":"ua1_Cr4tpVAq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705548535161,"user_tz":-420,"elapsed":341,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"499339de-f183-43f8-87c3-d0218b06ec01"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized: ['วัน', 'นี้', 'ตื่น', 'สาย', 'จึง', 'เข้า', 'โรง', 'เรียน', 'ช้า', 'จาก', 'นั้น', 'ก็', 'ไป', 'หาขนม', 'กิน', 'รูปร่าง', 'ดอก', 'ไม้', 'เพราะ', 'เมื่อ', 'เช้า', 'ยัง', 'ไม่', 'ได้', 'กิน', 'อะไร', 'มาก', 'เลย']\n"]}]},{"cell_type":"markdown","source":["## Tokenization and Part-of-Speech Tagging"],"metadata":{"id":"JuQuh_qIpaZO"}},{"cell_type":"code","source":["import pythainlp\n","\n","text = \"ในยุคที่ขายของออนไลน์เต็มไปด้วยคู่แข่งมากมายที่ขายสินค้าชนิดเดียวกันหรือคล้ายกัน วิธีที่จะทำให้สินค้าของคุณโดดเด่นเตะตาลูกค้าแถมสร้างความเชื่อมั่นในสรรพคุณได้มากที่สุดนั่นก็คือการรีวิวสินค้า แต่วิธีการรีวิวสินค้าให้น่าสนใจนั้นต้องทำอย่างไรถึงจะสามารถสร้างความมั่นใจให้ลูกค้าจนกระทั่งพวกเขายอมสั่งซื้อสินค้าของคุณได้\"\n","tokens = pythainlp.word_tokenize(text)\n","pos_tags = pythainlp.pos_tag(tokens)\n","print(\"Tokenized:\", tokens)\n","print(\"Part-of-Speech Tags:\", pos_tags)"],"metadata":{"id":"RQPU_XJFpePS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705548681332,"user_tz":-420,"elapsed":337,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"803cf716-a9cb-438e-ce4f-80159d9de1b7"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized: ['ใน', 'ยุค', 'ที่', 'ขายของ', 'ออนไลน์', 'เต็มไปด้วย', 'คู่แข่ง', 'มากมาย', 'ที่', 'ขาย', 'สินค้า', 'ชนิด', 'เดียวกัน', 'หรือ', 'คล้าย', 'กัน', ' ', 'วิธี', 'ที่จะ', 'ทำให้', 'สินค้า', 'ของ', 'คุณ', 'โดดเด่น', 'เตะตา', 'ลูกค้า', 'แถม', 'สร้าง', 'ความเชื่อมั่น', 'ใน', 'สรรพคุณ', 'ได้', 'มาก', 'ที่สุด', 'นั่น', 'ก็', 'คือ', 'การ', 'รีวิว', 'สินค้า', ' ', 'แต่', 'วิธีการ', 'รีวิว', 'สินค้า', 'ให้', 'น่าสนใจ', 'นั้น', 'ต้อง', 'ทำ', 'อย่างไร', 'ถึง', 'จะ', 'สามารถ', 'สร้าง', 'ความมั่นใจ', 'ให้', 'ลูกค้า', 'จนกระทั่ง', 'พวกเขา', 'ยอม', 'สั่งซื้อ', 'สินค้า', 'ของ', 'คุณ', 'ได้']\n","Part-of-Speech Tags: [('ใน', 'RPRE'), ('ยุค', 'NCMN'), ('ที่', 'PREL'), ('ขายของ', 'NCMN'), ('ออนไลน์', 'NCMN'), ('เต็มไปด้วย', 'RPRE'), ('คู่แข่ง', 'NCMN'), ('มากมาย', 'ADVN'), ('ที่', 'PREL'), ('ขาย', 'VACT'), ('สินค้า', 'NCMN'), ('ชนิด', 'NCMN'), ('เดียวกัน', 'DDAC'), ('หรือ', 'JCRG'), ('คล้าย', 'VSTA'), ('กัน', 'ADVN'), (' ', 'PUNC'), ('วิธี', 'NCMN'), ('ที่จะ', 'JSBR'), ('ทำให้', 'VACT'), ('สินค้า', 'NCMN'), ('ของ', 'RPRE'), ('คุณ', 'PPRS'), ('โดดเด่น', 'NPRP'), ('เตะตา', 'VACT'), ('ลูกค้า', 'NCMN'), ('แถม', 'NCMN'), ('สร้าง', 'VACT'), ('ความเชื่อมั่น', 'NCMN'), ('ใน', 'RPRE'), ('สรรพคุณ', 'NCMN'), ('ได้', 'XVAE'), ('มาก', 'ADVN'), ('ที่สุด', 'ADVN'), ('นั่น', 'PDMN'), ('ก็', 'JSBR'), ('คือ', 'VSTA'), ('การ', 'FIXN'), ('รีวิว', 'VACT'), ('สินค้า', 'NCMN'), (' ', 'PUNC'), ('แต่', 'JCRG'), ('วิธีการ', 'NCMN'), ('รีวิว', 'VACT'), ('สินค้า', 'NCMN'), ('ให้', 'JSBR'), ('น่าสนใจ', 'VSTA'), ('นั้น', 'DDAC'), ('ต้อง', 'XVMM'), ('ทำ', 'VACT'), ('อย่างไร', 'PNTR'), ('ถึง', 'RPRE'), ('จะ', 'XVBM'), ('สามารถ', 'XVAM'), ('สร้าง', 'VACT'), ('ความมั่นใจ', 'NCMN'), ('ให้', 'JSBR'), ('ลูกค้า', 'NCMN'), ('จนกระทั่ง', 'JSBR'), ('พวกเขา', 'VACT'), ('ยอม', 'VACT'), ('สั่งซื้อ', 'VACT'), ('สินค้า', 'NCMN'), ('ของ', 'RPRE'), ('คุณ', 'NCMN'), ('ได้', 'XVAE')]\n"]}]},{"cell_type":"markdown","source":["## Named Entity Recognition (NER)"],"metadata":{"id":"YBRX9QOIpg5n"}},{"cell_type":"code","source":["from pythainlp.tag import NER\n","\n","text = \"ประเทศไทยเป็นประเทศที่มีประชากรมากมาย\"\n","ner = NER(\"thainer\")\n","entities = ner.tag(text)\n","print(\"Entities:\", entities)"],"metadata":{"id":"wUVbEBuHpkKO","colab":{"base_uri":"https://localhost:8080/","height":101,"referenced_widgets":["447a123931b0465d9836f6fe2d38a2dd","f5dc40770b6547a887ea0c5671403a84","01664120a4364798bb89ebe303725d63","96f04c2992d94651b7673ee3b69f5924","56e89d92c5374ddcad0fb790e9eb8ddf","10383374dd2343ee84f120023812bb54","f642252716e44969ba20d5b9c5efd16c","2aef80e0e0fc42d1b23ddf95b597fd1f","c175f78b89764f76803e564a2d80f56c","99677a9113f44f7e93fd2b756943d37b","8c355a76379f4b68b9976957ca0bf0a3"]},"executionInfo":{"status":"ok","timestamp":1705546909403,"user_tz":-420,"elapsed":1744,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"7c511009-cd72-452c-901d-ec614b0db5d7"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Corpus: thainer-1.4\n","- Downloading: thainer-1.4 1.4\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1872468 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"447a123931b0465d9836f6fe2d38a2dd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Entities: [('ประเทศ', 'B-LOCATION'), ('ไทย', 'I-LOCATION'), ('เป็น', 'O'), ('ประเทศ', 'O'), ('ที่', 'O'), ('มี', 'O'), ('ประชากร', 'O'), ('มากมาย', 'O')]\n"]}]},{"cell_type":"markdown","source":["## Thai Word Segmentation"],"metadata":{"id":"RHxRGx94prjR"}},{"cell_type":"code","source":["import pythainlp\n","\n","text = \"คนไทยมีความภูมิใจในภาษาไทยของตน\"\n","segmented_text = pythainlp.word_tokenize(text, engine=\"newmm\") # engine: attacut, deepcut, ..., etc.\n","print(\"Segmented Text:\", segmented_text)"],"metadata":{"id":"75a_zJQspuw-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705547040988,"user_tz":-420,"elapsed":357,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"e1d65324-cef1-47ee-c798-f8c48b83041e"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Segmented Text: ['คนไทย', 'มี', 'ความภูมิใจ', 'ใน', 'ภาษาไทย', 'ของ', 'ตน']\n"]}]},{"cell_type":"markdown","source":["## Information Retrieval with TF-IDF\n"],"metadata":{"id":"StHoC_bPp2fb"}},{"cell_type":"code","source":["import pythainlp\n","from pythainlp.tokenize import word_tokenize\n","from pythainlp.corpus import thai_stopwords\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import linear_kernel\n","\n","# Sample Thai movie dataset\n","movies = {\n","    \"movie1\": \"กลุ่มเพื่อนผจญภัยที่น่าตื่นเต้นในป่าสมุทรอเมซอน\",\n","    \"movie2\": \"หุ่นยนต์ที่ถูกพลังงาน AI พัฒนาความรู้สึกคล้ายมนุษย์และสงสัยถึงการมีชีวิต\",\n","    \"movie3\": \"รอมคอมแห่งความฮาตั้งใจในใจกลางกรุงเทพฯ สำรวจความซับซ้อนของความสัมพันธ์ในยุคปัจจุบัน\",\n","    \"movie4\": \"รายลับที่น่าตื่นเต้นเปิดเผยเมื่อนักสืบค้นหาความจริงที่อยู่เบื้องหลังเหตุการณ์ที่ไม่คาดคิด\",\n","}\n","\n","# Preprocess and tokenize the movie dataset\n","processed_movies = [\" \".join(word_tokenize(desc, engine=\"newmm\")) for desc in movies.values()]\n","\n","print(processed_movies)\n","\n","# TF-IDF Vectorizer\n","vectorizer = TfidfVectorizer(stop_words=list(thai_stopwords()))\n","tfidf_matrix = vectorizer.fit_transform(processed_movies)\n","\n","# Function to retrieve movies based on user query using TF-IDF\n","def retrieve_movies_tfidf(query):\n","    query_vec = vectorizer.transform([query])\n","    cosine_similarities = linear_kernel(query_vec, tfidf_matrix).flatten()\n","    movie_scores = list(zip(movies.keys(), cosine_similarities))\n","    movie_scores.sort(key=lambda x: x[1], reverse=True)\n","\n","    return [movie_id for movie_id, score in movie_scores if score > 0]\n","\n","# Example usage\n","user_query = input(\"กรุณากรอกคำค้น: \")\n","\n","if user_query.lower() in ['exit', 'quit', 'ลาก่อน']:\n","    print(\"ลาก่อนครับ\")\n","else:\n","    retrieved_movies = retrieve_movies_tfidf(user_query)\n","\n","    if not retrieved_movies:\n","        print(\"ไม่พบหนังที่เกี่ยวข้อง\")\n","    else:\n","        print(\"หนังที่เกี่ยวข้อง:\")\n","        for movie_id in retrieved_movies:\n","            print(f\"- {movie_id}: {movies[movie_id]}\")"],"metadata":{"id":"AYoLufMip6vO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705547549032,"user_tz":-420,"elapsed":35236,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"d6beecc9-0623-4e09-ed6d-bfa74c60f9f0"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["['กลุ่ม เพื่อน ผจญภัย ที่ น่าตื่นเต้น ใน ป่า สมุทร อ เม ซอน', 'หุ่นยนต์ ที่ ถูก พลังงาน   AI   พัฒนา ความรู้สึก คล้าย มนุษย์ และ สงสัย ถึง การ มีชีวิต', 'รอม คอม แห่ง ความ ฮา ตั้งใจ ใน ใจกลาง กรุงเทพฯ   สำรวจ ความ ซับซ้อน ของ ความสัมพันธ์ ใน ยุคปัจจุบัน', 'ราย ลับ ที่ น่าตื่นเต้น เปิดเผย เมื่อ นักสืบ ค้นหา ความจริง ที่อยู่ เบื้องหลัง เหตุการณ์ ที่ ไม่ คาดคิด']\n","กรุณากรอกคำค้น: นักส์บกรุงเทพ\n","หนังที่เกี่ยวข้อง:\n","- movie4: รายลับที่น่าตื่นเต้นเปิดเผยเมื่อนักสืบค้นหาความจริงที่อยู่เบื้องหลังเหตุการณ์ที่ไม่คาดคิด\n"]}]},{"cell_type":"markdown","source":["## Word Vector"],"metadata":{"id":"4zD5h5jqqCYm"}},{"cell_type":"code","source":["import pythainlp\n","from pythainlp.word_vector  import WordVector\n","\n","\n","# Train custom word embeddings\n","wv = WordVector()\n","words = ['ดีไซน์เนอร์', 'พนักงานเงินเดือน', 'หมอ', 'เรือ']\n","wv.doesnt_match(words)"],"metadata":{"id":"ymjj7VdkqBJg","colab":{"base_uri":"https://localhost:8080/","height":119,"referenced_widgets":["6fb903ae245548f1be929c83cefe2c13","6d63b458d3c34c9cb5ec12eaebea20d4","9474e890177a41e2a7df15f2daf95fe2","d2abf9e6002e4dbdb9e7537800ea57ed","20e2f5df4f1f4decb0453bc15c0c5b10","ff6ebbd5d7fa4647920b62af9f19653a","da51e0970031479398372667e77bd406","8121fa30f9924ca4aa1eaf13f082a42f","2aead25f7b5a4989a0960da9856ea2ed","b4bf6b96174e48d59d913ce6800af28d","6a01748484f646f1bcf7c9c0437cb844"]},"executionInfo":{"status":"ok","timestamp":1705547562928,"user_tz":-420,"elapsed":3181,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"8af2dd79-c1d6-4000-b50f-f9da273e7b6f"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Corpus: thai2fit_wv\n","- Downloading: thai2fit_wv 0.1\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/62452646 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fb903ae245548f1be929c83cefe2c13"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.keyedvectors:vectors for words {'พนักงานเงินเดือน', 'ดีไซน์เนอร์'} are not present in the model, ignoring these words\n"]},{"output_type":"execute_result","data":{"text/plain":["'เรือ'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["list_positive = ['ประเทศ', 'ไทย', 'จีน', 'ญี่ปุ่น']\n","list_negative = []\n","wv.most_similar_cosmul(list_positive, list_negative)\n"],"metadata":{"id":"iikvV_GRuPCd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705547615693,"user_tz":-420,"elapsed":340,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"9b838c07-f85c-4871-cc28-72625d6d50ef"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('ประเทศจีน', 0.22022424638271332),\n"," ('เกาหลี', 0.219687357544899),\n"," ('สหรัฐอเมริกา', 0.21660110354423523),\n"," ('ประเทศญี่ปุ่น', 0.21205861866474152),\n"," ('ประเทศไทย', 0.2115921974182129),\n"," ('เกาหลีใต้', 0.20321202278137207),\n"," ('อังกฤษ', 0.19610872864723206),\n"," ('ฮ่องกง', 0.1928885132074356),\n"," ('ฝรั่งเศส', 0.18383873999118805),\n"," ('พม่า', 0.18369348347187042)]"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["list_positive = ['ประเทศ', 'ไทย', 'จีน', 'ญี่ปุ่น']\n","list_negative = ['อเมริกา']\n","wv.most_similar_cosmul(list_positive, list_negative)"],"metadata":{"id":"fqCgaqIDvToL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705547620249,"user_tz":-420,"elapsed":385,"user":{"displayName":"sittikorn chaloemkittichai","userId":"10878504066261628679"}},"outputId":"3b23232f-b80a-4ee4-a515-ca3b6bace18b"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('ประเทศไทย', 0.3278158903121948),\n"," ('เกาหลี', 0.3201899230480194),\n"," ('ประเทศจีน', 0.31755179166793823),\n"," ('พม่า', 0.30845439434051514),\n"," ('ประเทศญี่ปุ่น', 0.306713730096817),\n"," ('เกาหลีใต้', 0.3003999888896942),\n"," ('ลาว', 0.2995176911354065),\n"," ('คนไทย', 0.288502037525177),\n"," ('เวียดนาม', 0.287837952375412),\n"," ('ชาวไทย', 0.2848070561885834)]"]},"metadata":{},"execution_count":36}]}]}